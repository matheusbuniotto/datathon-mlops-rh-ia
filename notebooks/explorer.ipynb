{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8094f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd9c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.data_loader import load_applicants, load_jobs, load_prospects\n",
    "\n",
    "df_app = load_applicants(\"../data/raw/applicants.json\")\n",
    "df_vagas = load_jobs(\"../data/raw/vagas.json\")\n",
    "df_prospects = load_prospects(\"../data/raw/prospects.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e75b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_parquet(\"../data/processed/merged.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce56c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.embeddings import load_encoder\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/processed/merged.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de3c43a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# # Combinar campos úteis de vaga e currículo\n",
    "# df[\"texto_vaga\"] = df[\"titulo_vaga\"].fillna('') + \"\\n\" + df[\"principais_atividades\"].fillna('') + \"\\n\" + df[\"competencias\"].fillna('')\n",
    "# df[\"texto_cv\"] = df[\"cv\"].fillna('')\n",
    "\n",
    "# # Geração dos vetores\n",
    "# emb_vaga = encode_texts(encoder, df[\"texto_vaga\"].tolist())\n",
    "# emb_cv = encode_texts(encoder, df[\"texto_cv\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b187017",
   "metadata": {},
   "source": [
    "### Definir features categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563342ee",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_embeded = pd.read_parquet(\"../data/embeddings/combined_embeddings.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6089050",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna: nivel_profissional_vaga\n",
      "nivel_profissional_vaga\n",
      "Sênior                    21841\n",
      "Analista                  19265\n",
      "Pleno                     10148\n",
      "Júnior                     2140\n",
      "Especialista               1192\n",
      "Assistente                  780\n",
      "Gerente                     594\n",
      "Líder                       284\n",
      "Coordenador                 114\n",
      "Supervisor                  105\n",
      "Auxiliar                     57\n",
      "Trainee                      12\n",
      "Aprendiz                      6\n",
      "Técnico de Nível Médio        1\n",
      "Name: count, dtype: int64\n",
      "Coluna: nivel_ingles_vaga\n",
      "nivel_ingles_vaga\n",
      "Básico           20042\n",
      "Nenhum           13192\n",
      "Avançado         10539\n",
      "Fluente           6357\n",
      "Intermediário     5612\n",
      "Técnico            797\n",
      "Name: count, dtype: int64\n",
      "Coluna: nivel_profissional\n",
      "nivel_profissional\n",
      "                          44778\n",
      "Sênior                      175\n",
      "Especialista                 46\n",
      "Pleno                        27\n",
      "Analista                     16\n",
      "Líder                        15\n",
      "Júnior                        9\n",
      "Técnico de Nível Médio        2\n",
      "Gerente                       2\n",
      "Estagiário                    1\n",
      "Name: count, dtype: int64\n",
      "Coluna: nivel_academico\n",
      "nivel_academico\n",
      "                                 33129\n",
      "Ensino Superior Completo          5314\n",
      "Pós Graduação Completo            3042\n",
      "Ensino Superior Cursando          1256\n",
      "Ensino Superior Incompleto         574\n",
      "Pós Graduação Cursando             494\n",
      "Pós Graduação Incompleto           301\n",
      "Mestrado Completo                  284\n",
      "Ensino Técnico Completo            186\n",
      "Ensino Médio Completo              172\n",
      "Mestrado Incompleto                117\n",
      "Mestrado Cursando                   51\n",
      "Ensino Fundamental Completo         47\n",
      "Ensino Técnico Cursando             22\n",
      "Doutorado Incompleto                21\n",
      "Doutorado Cursando                  18\n",
      "Doutorado Completo                  14\n",
      "Ensino Técnico Incompleto            8\n",
      "Ensino Médio Incompleto              6\n",
      "Ensino Fundamental Incompleto        6\n",
      "Ensino Fundamental Cursando          6\n",
      "Ensino Médio Cursando                3\n",
      "Name: count, dtype: int64\n",
      "Coluna: nivel_ingles\n",
      "nivel_ingles\n",
      "                 33667\n",
      "Intermediário     3947\n",
      "Avançado          3162\n",
      "Básico            2775\n",
      "Fluente           1190\n",
      "Nenhum             330\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols_to_view = [\n",
    "    \"nivel_profissional_vaga\",\n",
    "    \"nivel_ingles_vaga\",\n",
    "\n",
    "    \"nivel_profissional\",\n",
    "    \"nivel_academico\",\n",
    "    \"nivel_ingles\"\n",
    "]\n",
    "\n",
    "\n",
    "for c in df_embeded[cols_to_view]:\n",
    "    if df_embeded[c].dtype == \"object\":\n",
    "        print(\"Coluna:\",c)\n",
    "        print(df_embeded[c].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e9798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo_vaga</th>\n",
       "      <th>codigo_candidato</th>\n",
       "      <th>nome_candidato</th>\n",
       "      <th>situacao</th>\n",
       "      <th>data_candidatura</th>\n",
       "      <th>ultima_atualizacao</th>\n",
       "      <th>comentario</th>\n",
       "      <th>recrutador</th>\n",
       "      <th>modalidade</th>\n",
       "      <th>titulo_vaga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4530</td>\n",
       "      <td>25529</td>\n",
       "      <td>Srta. Isabela Cavalcante</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>22-03-2021</td>\n",
       "      <td>23-03-2021</td>\n",
       "      <td>encaminhado para  - R$ 6.000,00 – CLT Full , n...</td>\n",
       "      <td>Ana Lívia Moreira</td>\n",
       "      <td></td>\n",
       "      <td>CONSULTOR CONTROL M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  codigo_vaga codigo_candidato            nome_candidato  \\\n",
       "1        4530            25529  Srta. Isabela Cavalcante   \n",
       "\n",
       "                      situacao data_candidatura ultima_atualizacao  \\\n",
       "1  Encaminhado ao Requisitante       22-03-2021         23-03-2021   \n",
       "\n",
       "                                          comentario         recrutador  \\\n",
       "1  encaminhado para  - R$ 6.000,00 – CLT Full , n...  Ana Lívia Moreira   \n",
       "\n",
       "  modalidade          titulo_vaga  \n",
       "1             CONSULTOR CONTROL M  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects.query(\"nome_candidato =='Srta. Isabela Cavalcante'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609421b",
   "metadata": {},
   "source": [
    "### Teste e treino split - teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c96e68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-08 10:41:30.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.stages.data_split_stage\u001b[0m:\u001b[36msplit_dataset_by_vaga\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1m[Split] Iniciando divisão do dataset por vaga...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'vaga_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github.com/datathon-mlops-rh-ia/.venv/lib64/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'vaga_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_split_stage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_dataset_by_vaga\n\u001b[32m      2\u001b[39m df = pd.read_parquet(\u001b[33m\"\u001b[39m\u001b[33m../data/processed/rank_ready.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_train, df_val, df_test = \u001b[43msplit_dataset_by_vaga\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github.com/datathon-mlops-rh-ia/app/stages/data_split_stage.py:10\u001b[39m, in \u001b[36msplit_dataset_by_vaga\u001b[39m\u001b[34m(df, test_size, val_size, random_state)\u001b[39m\n\u001b[32m      7\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m[Split] Iniciando divisão do dataset por vaga...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m gss = GroupShuffleSplit(n_splits=\u001b[32m1\u001b[39m, test_size=test_size, random_state=random_state)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m train_idx, test_idx = \u001b[38;5;28mnext\u001b[39m(gss.split(df, groups=\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvaga_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m     12\u001b[39m df_train = df.iloc[train_idx]\n\u001b[32m     13\u001b[39m df_test = df.iloc[test_idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github.com/datathon-mlops-rh-ia/.venv/lib64/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/github.com/datathon-mlops-rh-ia/.venv/lib64/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'vaga_id'"
     ]
    }
   ],
   "source": [
    "from app.stages.data_split_stage import split_dataset_by_vaga\n",
    "df = pd.read_parquet(\"../data/processed/rank_ready.parquet\")\n",
    "df_train, df_val, df_test = split_dataset_by_vaga(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
