# RecrutaIA Rank - Datathon MLOps RH IA

## Vis√£o Geral

Este projeto √© um pipeline MLOps completo para classifica√ß√£o de candidatos para vagas de emprego usando aprendizado de m√°quina e pr√°ticas modernas de MLOps. Foi desenvolvido para o desafio Datathon MLOps RH IA e demonstra uma abordagem pronta para produ√ß√£o para implementar, monitorar e avaliar modelos de classifica√ß√£o.

## Principais Caracter√≠sticas

- **FastAPI**: API REST para servir predi√ß√µes de classifica√ß√£o de candidatos
- **Pipeline de Machine Learning**: Pr√©-processamento de dados, engenharia de features, treinamento de modelo e predi√ß√£o usando LightGBM e scikit-learn
- **Monitoramento**: Prometheus e Grafana integrados para monitoramento em tempo real da API e modelo
- **Dockerizado**: Todos os servi√ßos (API, Prometheus, Grafana) executam em containers para f√°cil implanta√ß√£o
- **Notebooks**: Para explora√ß√£o de dados, verifica√ß√£o de embeddings e testes com dados mock
- **Avalia√ß√£o**: Scripts e ferramentas para avalia√ß√£o robusta do modelo (NDCG, MAP, an√°lise de grupos)
- **Reprodutibilidade**: Todas as depend√™ncias s√£o fixas e rastreadas para ambientes consistentes

## üöÄ In√≠cio R√°pido: Docker (Recomendado)

**Quer apenas ver funcionando? Um comando te d√° um sistema ML completo:**

```bash
# Clone e inicie tudo
git clone https://github.com/matheusbuniotto/datathon-mlops-rh-ia.git
cd datathon-mlops-rh-ia
docker-compose up --build
```

**üéØ O que voc√™ obt√©m instantaneamente:**
- ‚úÖ **API ML** com modelos treinados ‚Üí `http://localhost:8000`
- ‚úÖ **Dashboard Grafana** (sem login) ‚Üí `http://localhost:3000`  
- ‚úÖ **M√©tricas Prometheus** ‚Üí `http://localhost:9090`
- ‚úÖ **Zero configura√ß√£o** - tudo funciona direto da caixa

**üß™ Teste a API:**
```bash
# Verifica√ß√£o de sa√∫de
curl http://localhost:8000/health

# Obter posi√ß√µes de trabalho dispon√≠veis
curl "http://localhost:8000/v1/list-vagas"

# Obter candidatos ranqueados
curl "http://localhost:8000/v1/recommend_ranked?vaga_id=1650&top_n=5"
```

**üìä Monitore no Grafana:**
- Taxas de requisi√ß√£o, tempos de resposta, predi√ß√µes ML
- Detec√ß√£o de drift de dados e performance do modelo
- Dashboards em tempo real com m√©tricas de neg√≥cio

## üõ†Ô∏è Desenvolvimento: Pipeline ML Completo

**Quer treinar seus pr√≥prios modelos ou trabalhar com dados reais? Aqui est√° o fluxo completo:**

### 1. Configura√ß√£o do Ambiente
```bash
# Instale depend√™ncias (recomendado: use uv)
uv sync

# Instale o pacote em modo desenvolvimento
uv pip install -e .
```

### 2. Configura√ß√£o Interativa com Op√ß√µes de Dados
```bash
# Configura√ß√£o interativa - escolha dados de amostra ou reais
uv run scripts/quick_start.py

# Siga as instru√ß√µes para selecionar:
# 1. Dados de amostra (100 registros) - Demo r√°pida
# 2. Dados reais (download autom√°tico) - Performance completa
```

### 3. Pipeline e Treinamento Manual
```bash
# Baixar dados de produ√ß√£o reais (se necess√°rio)
uv run scripts/download_data.py

# Executar pipeline completo de dados
uv run app/pipeline_run_all.py

# Treinar modelo com ajuste de hiperpar√¢metros
uv run app/model/train_ranker_tuning.py dev

# Avaliar performance do modelo
uv run app/model/evaluate_ranker.py

# Executar API local
uvicorn services.api.main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Ferramentas de Desenvolvimento
```bash
# Executar testes
pytest

# Qualidade do c√≥digo
uv run ruff check .
uv run ruff format .
```

### üìä Informa√ß√µes sobre Dados

**Dados de Amostra (inclu√≠dos no reposit√≥rio):**
- `sample_applicants.json` (50 candidatos, 212KB)
- `sample_vagas.json` (20 posi√ß√µes, 44KB)  
- `sample_prospects.json` (30 prospects, 36KB)

**Dados de Produ√ß√£o (baixados automaticamente do GitHub Releases):**
- `applicants.json` (194MB) - Base completa de candidatos
- `vagas.json` (37MB) - Posi√ß√µes de trabalho completas
- `prospects.json` (21MB) - Todos os dados de prospects

## Principais Endpoints

- `GET /health`: Verifica√ß√£o de sa√∫de do servi√ßo
- `GET /v1/recommend_ranked?vaga_id={id}&top_n={n}`: Obter recomenda√ß√µes de candidatos ranqueados para uma vaga espec√≠fica
- `GET /v1/list-vagas`: Retorna todos os IDs de vagas dispon√≠veis para usar no endpoint de recomenda√ß√£o
- `GET /metrics`: Endpoint de m√©tricas do Prometheus

## Vis√£o Geral da Arquitetura

O sistema segue uma arquitetura de pipeline ML em est√°gios:

### Componentes Principais

1. **Pipeline de Dados (`app/pipeline.py`)**: Orquestra o fluxo completo de processamento de dados
   - Convers√£o de dados JSON brutos ‚Üí Parquet
   - Fus√£o de dados baseada em SQL via DuckDB
   - Gera√ß√£o de embeddings usando sentence-transformers
   - Prepara√ß√£o do dataset de classifica√ß√£o

2. **Est√°gios do Pipeline ML (`app/stages/`)**:
   - `embeddings_stage.py`: Gera embeddings sem√¢nticos para descri√ß√µes de vagas e perfis de candidatos
   - `ranking_preparation_stage.py`: Cria dados de treinamento para modelo de classifica√ß√£o com alvos de relev√¢ncia
   - `feature_engineering_stage.py`: Engenharia de features e pr√©-processamento
   - `data_split_stage.py`: Divis√£o de dados para treinamento/valida√ß√£o/teste

3. **Treinamento do Modelo (`app/model/`)**:
   - `train_ranker.py`: Treinamento do modelo de classifica√ß√£o LightGBM
   - `train_ranker_tuning.py`: Otimiza√ß√£o de hiperpar√¢metros com Optuna
   - `evaluate_ranker.py`: Avalia√ß√£o do modelo com m√©tricas de classifica√ß√£o (NDCG, MAP)

4. **Servi√ßo de API (`services/api/`)**:
   - API REST baseada em FastAPI
   - Predi√ß√µes de classifica√ß√£o de candidatos em tempo real
   - Integra√ß√£o com m√©tricas do Prometheus
   - Monitoramento de sa√∫de

5. **Stack de Monitoramento (`services/monitoring/`)**:
   - Prometheus para coleta de m√©tricas
   - Grafana para visualiza√ß√£o e dashboards
   - M√©tricas de neg√≥cio personalizadas e monitoramento de drift de dados

### Fluxo de Dados

```
Dados Brutos (JSON) ‚Üí Pipeline de Dados ‚Üí Embeddings ‚Üí Engenharia de Features ‚Üí Treinamento do Modelo ‚Üí Implanta√ß√£o da API
                                             ‚Üì
                                      Monitoramento & Avalia√ß√£o
```

### Artefatos de Dados Principais

- `data/processed/merged.parquet`: Dados de recrutamento unificados
- `data/embeddings/combined_embeddings.parquet`: Embeddings sem√¢nticos para todas as entidades
- `data/model_input/`: Features pr√©-processadas prontas para treinamento do modelo
- `models/lgbm_ranker.pkl`: Modelo LightGBM de classifica√ß√£o treinado

## Monitoramento

- **Prometheus**: `http://localhost:9090` (coleta de m√©tricas)
- **Grafana**: `http://localhost:3000` (admin/admin) (dashboards e visualiza√ß√£o)
- M√©tricas personalizadas para performance da API e predi√ß√µes do modelo

## Exemplos de Chamadas √† API

```bash
# Obter lista de todos os IDs de vagas dispon√≠veis
curl "http://localhost:8000/v1/list-vagas"

# Obter recomenda√ß√µes de candidatos ranqueados para vagas espec√≠ficas
curl "http://localhost:8000/v1/recommend_ranked?vaga_id=1650&top_n=5"
curl "http://localhost:8000/v1/recommend_ranked?vaga_id=6647&top_n=10"
```

## Requisitos

- Docker & Docker Compose
- Python 3.11+ (para desenvolvimento local)
- Veja `requirements-dev.txt` para depend√™ncias

## Detalhes T√©cnicos

- **Framework ML**: LightGBM para classifica√ß√£o com learning-to-rank baseado em grupos
- **Embeddings**: Gerados usando sentence-transformers (modelos multil√≠ngues)
- **Processamento de Dados**: DuckDB para opera√ß√µes SQL eficientes e processamento de dados
- **Framework de API**: FastAPI com integra√ß√£o de m√©tricas do Prometheus
- **Containeriza√ß√£o**: Todos os servi√ßos executam em containers Docker para implanta√ß√£o consistente
- **Avalia√ß√£o do Modelo**: M√©tricas espec√≠ficas de classifica√ß√£o (NDCG, MAP)
- **Monitoramento**: Capacidades de monitoramento de drift de dados em tempo real

## Dicas de Desenvolvimento

- Use `uv` para gerenciamento mais r√°pido de depend√™ncias quando dispon√≠vel
- Os notebooks em `notebooks/` s√£o para explora√ß√£o e podem precisar de limpeza
- Artefatos do modelo s√£o salvos nos diret√≥rios `app/model/` e `models/`
- Todos os est√°gios principais do pipeline t√™m arquivos de teste correspondentes
- Ruff est√° configurado para excluir notebooks Jupyter do linting
