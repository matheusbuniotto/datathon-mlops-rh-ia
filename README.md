# RecrutaIA Rank - Sistema de Rankeamento de Candidatos

## Sobre o Projeto

Este projeto √© um pipeline MLOps completo para classifica√ß√£o de candidatos para vagas de emprego usando aprendizado de m√°quina e pr√°ticas modernas de MLOps. Desenvolvido como projeto de conclus√£o do curso de **Machine Learning Engineering da FIAP**, demonstra uma abordagem pr√°tica e profissional para implementar, monitorar e avaliar modelos de classifica√ß√£o em produ√ß√£o.

## Principais Caracter√≠sticas

- **API de Machine Learning**: API REST usando FastAPI para servir predi√ß√µes de classifica√ß√£o de candidatos em tempo real
- **Pipeline MLOps Completo**: Pr√©-processamento de dados, engenharia de features, treinamento automatizado e avalia√ß√£o usando LightGBM
- **Monitoramento Profissional**: Stack completa com Prometheus e Grafana para observabilidade, m√©tricas de neg√≥cio e detec√ß√£o de data drift
- **Containeriza√ß√£o**: Arquitetura cloud-native com Docker e Docker Compose para deploy consistente
- **Embeddings Sem√¢nticos**: Utiliza sentence-transformers para an√°lise inteligente de perfis e descri√ß√µes de vagas
- **Avalia√ß√£o Robusta**: M√©tricas espec√≠ficas para ranking (NDCG, MAP) com an√°lise detalhada de performance
- **Reprodutibilidade**: Ambiente completamente versionado e depend√™ncias controladas

## üöÄ Demo R√°pida: Sistema Completo em 1 Comando

**Quer ver o sistema funcionando? Execute um comando e tenha uma solu√ß√£o MLOps completa rodando:**

```bash
# Clone e inicie tudo
git clone https://github.com/matheusbuniotto/datathon-mlops-rh-ia.git
cd datathon-mlops-rh-ia
docker-compose up --build
```

**üéØ O que voc√™ obt√©m instantaneamente:**
- ‚úÖ **API de ML em produ√ß√£o** com modelos treinados ‚Üí `http://localhost:8000`
- ‚úÖ **Dashboard de monitoramento** profissional ‚Üí `http://localhost:3000`  
- ‚úÖ **Coleta de m√©tricas** em tempo real ‚Üí `http://localhost:9090`
- ‚úÖ **Zero configura√ß√£o** - ambiente pronto para demonstra√ß√£o

**üß™ Teste a API:**
```bash
# Verifica√ß√£o de sa√∫de
curl http://localhost:8000/health

# Obter posi√ß√µes de trabalho dispon√≠veis
curl "http://localhost:8000/v1/list-vagas"

# Obter candidatos ranqueados
curl "http://localhost:8000/v1/recommend_ranked?vaga_id=1650&top_n=5"
```

**üìä Explore o Dashboard:**
- M√©tricas de performance da API e lat√™ncia
- An√°lise de drift de dados e qualidade do modelo
- Dashboards profissionais com insights de neg√≥cio

## üõ†Ô∏è Desenvolvimento: Explorando o Pipeline Completo

**Interessado em entender como tudo funciona? Aqui est√° o workflow completo de desenvolvimento:**

### 1. Configura√ß√£o do Ambiente
```bash
# Instale depend√™ncias (recomendado: use uv)
uv sync

# Instale o pacote em modo desenvolvimento
uv pip install -e .
```

### 2. Configura√ß√£o Interativa com Op√ß√µes de Dados
```bash
# Configura√ß√£o interativa - escolha dados de amostra ou reais
uv run scripts/quick_start.py

# Siga as instru√ß√µes para selecionar:
# 1. Dados de amostra (100 registros) - Demo r√°pida
# 2. Dados reais (download autom√°tico) - Performance completa
```

### 3. Pipeline e Treinamento Manual
```bash
# Baixar dados de produ√ß√£o reais (se necess√°rio)
uv run scripts/download_data.py

# Executar pipeline completo de dados
uv run app/pipeline_run_all.py

# Treinar modelo com ajuste de hiperpar√¢metros
uv run app/model/train_ranker_tuning.py dev

# Avaliar performance do modelo
uv run app/model/evaluate_ranker.py

# Executar API local
uvicorn services.api.main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Ferramentas de Desenvolvimento
```bash
# Executar testes
pytest

# Qualidade do c√≥digo
uv run ruff check .
uv run ruff format .
```

### üìä Informa√ß√µes sobre Dados

**Dados de Amostra (inclu√≠dos no reposit√≥rio):**
- `sample_applicants.json` (50 candidatos, 212KB)
- `sample_vagas.json` (20 posi√ß√µes, 44KB)  
- `sample_prospects.json` (30 prospects, 36KB)

**Dados de Produ√ß√£o (baixados automaticamente do GitHub Releases):**
- `applicants.json` (194MB) - Base completa de candidatos
- `vagas.json` (37MB) - Posi√ß√µes de trabalho completas
- `prospects.json` (21MB) - Todos os dados de prospects

## Principais Endpoints

- `GET /health`: Verifica√ß√£o de sa√∫de do servi√ßo
- `GET /v1/recommend_ranked?vaga_id={id}&top_n={n}`: Obter recomenda√ß√µes de candidatos ranqueados para uma vaga espec√≠fica
- `GET /v1/list-vagas`: Retorna todos os IDs de vagas dispon√≠veis para usar no endpoint de recomenda√ß√£o
- `GET /metrics`: Endpoint de m√©tricas do Prometheus

## Vis√£o Geral da Arquitetura

O sistema segue uma arquitetura de pipeline ML em est√°gios:

### Componentes Principais

1. **Pipeline de Dados (`app/pipeline.py`)**: Orquestra o fluxo completo de processamento de dados
   - Convers√£o de dados JSON brutos ‚Üí Parquet
   - Fus√£o de dados baseada em SQL via DuckDB
   - Gera√ß√£o de embeddings usando sentence-transformers
   - Prepara√ß√£o do dataset de classifica√ß√£o

2. **Est√°gios do Pipeline ML (`app/stages/`)**:
   - `embeddings_stage.py`: Gera embeddings sem√¢nticos para descri√ß√µes de vagas e perfis de candidatos
   - `ranking_preparation_stage.py`: Cria dados de treinamento para modelo de classifica√ß√£o com alvos de relev√¢ncia
   - `feature_engineering_stage.py`: Engenharia de features e pr√©-processamento
   - `data_split_stage.py`: Divis√£o de dados para treinamento/valida√ß√£o/teste

3. **Treinamento do Modelo (`app/model/`)**:
   - `train_ranker.py`: Treinamento do modelo de classifica√ß√£o LightGBM
   - `train_ranker_tuning.py`: Otimiza√ß√£o de hiperpar√¢metros com Optuna
   - `evaluate_ranker.py`: Avalia√ß√£o do modelo com m√©tricas de classifica√ß√£o (NDCG, MAP)

4. **Servi√ßo de API (`services/api/`)**:
   - API REST baseada em FastAPI
   - Predi√ß√µes de classifica√ß√£o de candidatos em tempo real
   - Integra√ß√£o com m√©tricas do Prometheus
   - Monitoramento de sa√∫de

5. **Stack de Monitoramento (`services/monitoring/`)**:
   - Prometheus para coleta de m√©tricas
   - Grafana para visualiza√ß√£o e dashboards
   - M√©tricas de neg√≥cio personalizadas e monitoramento de drift de dados

### Fluxo de Dados

```
Dados Brutos (JSON) ‚Üí Pipeline de Dados ‚Üí Embeddings ‚Üí Engenharia de Features ‚Üí Treinamento do Modelo ‚Üí Implanta√ß√£o da API
                                             ‚Üì
                                      Monitoramento & Avalia√ß√£o
```

### Artefatos de Dados Principais

- `data/processed/merged.parquet`: Dados de recrutamento unificados
- `data/embeddings/combined_embeddings.parquet`: Embeddings sem√¢nticos para todas as entidades
- `data/model_input/`: Features pr√©-processadas prontas para treinamento do modelo
- `models/lgbm_ranker.pkl`: Modelo LightGBM de classifica√ß√£o treinado

## Monitoramento

- **Prometheus**: `http://localhost:9090` (coleta de m√©tricas)
- **Grafana**: `http://localhost:3000` (admin/admin) (dashboards e visualiza√ß√£o)
- M√©tricas personalizadas para performance da API e predi√ß√µes do modelo

## Exemplos de Chamadas √† API

```bash
# Obter lista de todos os IDs de vagas dispon√≠veis
curl "http://localhost:8000/v1/list-vagas"

# Obter recomenda√ß√µes de candidatos ranqueados para vagas espec√≠ficas
curl "http://localhost:8000/v1/recommend_ranked?vaga_id=1650&top_n=5"
curl "http://localhost:8000/v1/recommend_ranked?vaga_id=6647&top_n=10"
```

## Requisitos

- Docker & Docker Compose
- Python 3.11+ (para desenvolvimento local)
- Veja `requirements-dev.txt` para depend√™ncias

## Detalhes T√©cnicos

- **Framework ML**: LightGBM para classifica√ß√£o com learning-to-rank baseado em grupos
- **Embeddings**: Gerados usando sentence-transformers (modelos multil√≠ngues)
- **Processamento de Dados**: DuckDB para opera√ß√µes SQL eficientes e processamento de dados
- **Framework de API**: FastAPI com integra√ß√£o de m√©tricas do Prometheus
- **Containeriza√ß√£o**: Todos os servi√ßos executam em containers Docker para implanta√ß√£o consistente
- **Avalia√ß√£o do Modelo**: M√©tricas espec√≠ficas de classifica√ß√£o (NDCG, MAP)
- **Monitoramento**: Capacidades de monitoramento de drift de dados em tempo real

## Contexto Acad√™mico

Este projeto foi desenvolvido como **Projeto de Conclus√£o** do curso de **Machine Learning Engineering** da **FIAP** e implementa conceitos fundamentais de MLOps:

### Conceitos Aplicados
- **Versionamento de Modelos**: Controle completo de vers√µes de dados, c√≥digo e modelos
- **CI/CD para ML**: Pipeline automatizado de integra√ß√£o e deploy
- **Monitoramento em Produ√ß√£o**: Observabilidade completa com m√©tricas customizadas
- **Reproducibilidade**: Ambientes containerizados e depend√™ncias fixas  
- **Data Drift Detection**: Monitoramento de qualidade e mudan√ßas nos dados
- **Model Serving**: API profissional para servir modelos em produ√ß√£o

### Arquitetura Enterprise
O sistema demonstra uma arquitetura robusta seguindo boas pr√°ticas da ind√∫stria, adequada para ambientes corporativos e solu√ß√µes escal√°veis.

## Dicas de Desenvolvimento

- Use `uv` para gerenciamento mais r√°pido de depend√™ncias quando dispon√≠vel
- Os notebooks em `notebooks/` s√£o para explora√ß√£o e podem precisar de limpeza
- Artefatos do modelo s√£o salvos nos diret√≥rios `app/model/` e `models/`
- Todos os est√°gios principais do pipeline t√™m arquivos de teste correspondentes
- Ruff est√° configurado para excluir notebooks Jupyter do linting
